#!/usr/bin/python3

""" album-md5 creates and verifies checksums recursively. """

import argparse
import hashlib
import math
import os
import sys
import time

cwd = os.getcwd()


class Output(object):  # {{{1
    """ Handles printing to the screen and the state of the output. """

    # whether the last thing printed was a progress dot
    dot_last = False

    @staticmethod
    def clear_dot():  # {{{2
        """ Print a newline if the last thing printed was a progress dot. """

        if Output.dot_last:
            print("")
            Output.dot_last = False

    @staticmethod
    def dot():  # {{{2
        """ Output a progress dot. """

        print(".", end="")
        sys.stdout.flush()
        Output.dot_last = True

    @staticmethod
    def print(*arguments):  # {{{2
        """ Output the given message. """

        Output.clear_dot()
        print(*arguments)

    @staticmethod
    def error(*arguments):  # {{{2
        """ Output a given message as error message. """

        Output.clear_dot()
        print(*arguments, file=sys.stderr)

OUT = Output.print
ERR = Output.error


def parse_arguments():  # {{{1
    """ Parse commandline arguments and return the argparse object. """

    parser = argparse.ArgumentParser(
        description='Recursively create and verify md5 checksums in '
                    'directories',
        epilog='By default, only directories without any subdirectories '
               '("leaves") will be processed. This can be overridden with the '
               '-f option. All files in a directory (except the checksum '
               'filename) will be hashed and either stored in the MD5 file or '
               'checked against it, depending on operation mode. If no '
               'operation mode is given, checking mode will be selected.',
        prog='album-md5')
    group = parser.add_mutually_exclusive_group()
    group.add_argument(
        '-c', '--create', action='store_true',
        help='create checksums and write them to files')
    group.add_argument(
        '-p', '--paths', action='store_true',
        help='only check paths, don\'t compare checksums (faster)')
    parser.add_argument(
        '-F', '--filename', action='store', default='Checksums.md5',
        metavar='name',
        help='name of checksum files (default: Checksums.md5, use \'all\' to '
             'use any *.md5 file in checking mode)')
    parser.add_argument(
        '-s', '--skip', action='store', default=0, type=int, metavar='n',
        help='skip given number of dirs (to resume an aborted run)')
    parser.add_argument(
        '-l', '--follow-links', action='store_true',
        help='follow symlink instead of ignoring them')
    parser.add_argument(
        '-n', '--number', action='store', default=-1, type=int, metavar='n',
        help='only process this many dirs (after the skipped ones)')
    parser.add_argument(
        '-f', '--force', action='store_true',
        help='force processing of files in dirs with subdirs')
    parser.add_argument(
        '-o', '--overwrite', action='store_true',
        help='override checksum files without asking')
    parser.add_argument(
        '--no-missing-checksums', action='store_true',
        help='Don\'t warn on directories without checksum files')
    parser.add_argument(
        'locations', metavar='dir', type=str, nargs='*',
        help='a list of directories to parse (default is current dir)')
    group = parser.add_mutually_exclusive_group()
    group.add_argument(
        '-q', '--quiet', action='count', default=0,
        help='less progress output (-q: print dots instead of paths, -qq: '
             'print no progress at all, -qqq: suppress warnings about missing '
             'checksum files)')
    group.add_argument(
        '-v', '--verbose', action='store_true',
        help='print the file that is being checked')

    parsed_args = parser.parse_args()

    # clean-up of input
    if parsed_args.quiet > 3:
        parsed_args.quiet = 3
    if parsed_args.filename == "all":
        if parsed_args.create:
            print("Error: cannot combine '-F all' with '-c'.", file=sys.stderr)
            exit(1)
    else:
        parsed_args.filename = os.path.basename(parsed_args.filename)

    # use current dir if no dir to process was given
    if not parsed_args.locations:
        parsed_args.locations.append(cwd)

    return parsed_args

args = parse_arguments()


class State(object):  # {{{1
    """ Encapsulate al necessary state variables for the recursion. """

    # number of matching directories (i.e. those that contain files to process)
    dircount = 0
    # number of matching directories to skip at the beginning
    skip = 0
    # number of matching directories after which to exit
    limit = 0
    # number of directories skipped due to answer to overwrite question
    skipped_overwrites = 0
    # number of files processed
    files = 0
    # number of failed md5 checks
    fails = 0
    # number of passed md5 checks
    passes = 0
    # number of files listed in md5, but physically missing
    files_missing = 0
    # number of files not listed in existing md5 file
    not_in_md5 = 0
    # number of matching directories without md5 file
    md5_missing = 0
    # number of bytes processed during hasing
    total_hashed_bytes = 0

    # answer flags for the question about already existing md5 files
    # overwrite all following md5 collisions
    overwrite_all = False
    # skip all following directories with md5 collisions
    skip_all = False
    # whether a question was asked (which means there was output)
    question_asked = False

    @staticmethod
    def set_from_arguments(arguments):
        """ Set relevant statistics according to main arguments. """

        State.skip = arguments.skip
        State.limit = arguments.number
        State.overwrite_all = args.overwrite

State.set_from_arguments(args)


class RecursionException(Exception):  # {{{1

    """ Base class for custom exceptions. """

    pass


def do_hash(path):  # {{{1
    """ Read the given file chunk by chunk and fead that to the digest. """

    # thanks: http://stackoverflow.com/questions/1131220/get-md5-hash-of-big-\
    # files-in-python
    md5 = hashlib.md5()
    with open(path, "rb") as infile:
        while True:
            data = infile.read(1048576)  # 1 MiB at a time
            if not data:
                break
            md5.update(data)
    return md5.hexdigest()


def gather_files(path, dirlist):  # {{{1
    """ Build sorted list of directories and files to process.

    Each entry is a tuple (path, size, filelist, checksum filelist). Directory
    paths end with a path separator. The 'size' for directories is the summed
    size of all the files to be hashed in that dir. The size for files is the
    actual filesize in byte. Directories that don't contain relevant files will
    not be listed, even if any of their subdirectories actually do.

    The resulting list looks like this:
    [
        ("/", 12345, ["/frotz", 12345], []),
        ("/A/B/", 96, [("/A/B/foo", 32), ("/A/B/bar", 64)], ["Checksums.md5"])
    ]
        """

    if not os.path.isdir(path):
        return 0
    if not path.endswith(os.path.sep):
        path += os.path.sep

    totalsize = 0

    # get and categorise directory content {{{2
    content = os.listdir(path)
    dirs = []
    files = []
    for item in content:
        fullpath = path + os.path.sep + item
        if os.path.islink(fullpath) and not args.follow_links:
            continue
        if os.path.isdir(fullpath):
            dirs.append(item)
        elif os.path.isfile(path + os.path.sep + item):
            files.append(item)

    # look for requested (or existing) checksum files {{{2
    if args.filename == "all":
        md5files = [f for f in files if f.lower().endswith(".md5")]
        md5files.sort()
    else:
        md5files = [args.filename] if args.filename in files else []
    # and remove them from the files to be checked
    for md5file in md5files:
        if md5file in files:
            files.remove(md5file)

    # gather relevant list of files in this directory {{{2
    if files and (not dirs or args.force):
        # only process if this dir is not excluded through constraint arguments
        if State.skip == 0 and State.limit != 0:
            files.sort()
            filelist = []
            for item in files:
                fullpath = path + os.path.sep + item
                size = os.path.getsize(fullpath)
                totalsize += size
                filelist.append(item)
            dirlist.append((path, totalsize, filelist, md5files))
            if State.limit != -1:
                State.limit -= 1
        else:
            if State.skip > 0:
                State.skip -= 1

    # recursive part: go through all subdirs {{{2
    dirs.sort()
    for item in dirs:
        if State.limit == 0:
            return totalsize
        totalsize += gather_files(path + item + os.path.sep, dirlist)
    return totalsize


def ask_checksum_overwrite():
    """ A checksum file would be overwritten. Ask how to proceed.

    Return True if proceed with the current directory. """

    if State.skip_all:
        return False
    if not State.overwrite_all:
        # put a newline behind the dots
        Output.clear_dot()
        while True:
            State.question_asked = True
            answer = input(
                ">>> Checksum file exists: (O)verwrite, "
                "o(v)erwrite all, (s)kip, skip al(l), (a)bort? ")
            if answer.lower() in "ovsla":
                break
        if answer == "o":
            return True
        elif answer == "v":
            State.overwrite_all = True
            return True
        elif answer == "a":
            raise RecursionException("aborted")
        elif answer == "l":
            State.skip_all = True
            return False
        elif answer == "s":
            return False


def process_files(filenum_width, path, files, checksum_files):  # {{{1
    """ Read checksum files and compare hashes in one directory. """

    # progress output {{{2
    # full output mode: print number of files and name of directory
    if args.quiet == 0 and (checksum_files or args.create):
        OUT(
            "Skipping " if State.skip_all else
            "Processing {0:>{1}} files in {2}".format(
                len(files), filenum_width,
                "." + path[len(cwd):] if path.startswith(cwd) else path)
        )

    if not checksum_files and not args.create and args.quiet < 3:
        if not args.no_missing_checksums:
            OUT("No checksum file in .{0}".format(
                path[len(cwd):] if path.startswith(cwd) else path))

    # reduced output: only print a dot for each directory
    elif args.quiet == 1:
        Output.dot()

    # the checksum file will be overwritten -> ask how to proceed {{{2
    if checksum_files and args.create and os.path.isfile(
            path + checksum_files[0]) and not ask_checksum_overwrite():
        State.skipped_overwrites += 1
        return 0

    checksums_paths = [path + f for f in checksum_files]
    checksums = {}
    oldsums = {}

    # read entries in MD5 file {{{2
    if not args.create:
        if checksum_files:
            for checksums_path in checksums_paths:
                try:
                    for line in open(checksums_path):
                        filename, md5 = line[34:-1], line[:32]
                        oldsums[filename] = md5
                        if filename not in files:
                            ERR(">>> '{0}': does not exist: '{1}'".format(
                                checksums_path, filename))
                            State.files_missing += 1
                except OSError as error:
                    ERR(">>> '{0}' while reading checksum file '{1}'".format(
                        error.args[1], checksums_path))
            if len(oldsums) == 0:
                return 0
        elif files:
            State.md5_missing += 1

    # process hashing results (compare with or write to files) {{{2
    hashed_bytes = 0
    if args.create or checksum_files:
        for filename in files:
            fullpath = path + filename

            oldsum = oldsums.get(filename)
            # want to check, but file does not exist in MD5
            if not args.create and not oldsum:
                ERR(">>> '{0}' not in any MD5 file.".format(
                    filename if args.quiet == 0 else fullpath))
                State.not_in_md5 += 1
            # want to create or check the md5
            elif not args.paths:
                if args.verbose:
                    OUT("Hashing '{0}'".format(fullpath))
                try:
                    checksums[filename] = do_hash(fullpath)
                    hashed_bytes += os.path.getsize(fullpath)
                    State.files += 1
                    if not args.create:
                        if oldsum != checksums[filename]:
                            raise Exception(0, 'checksum error')
                except Exception as exception:
                    ERR(">>> {0}: '{1}'".format(exception.args[1], filename))
                    State.fails += 1
                else:
                    State.passes += 1

    # write new checksum file {{{2
    if args.create:
        if files:
            try:
                with open(checksums_paths[0], "w") as md5_file:
                    for item in files:
                        print("{0} *{1}".format(checksums[item], item),
                              file=md5_file)
            except OSError as error:
                ERR(">>> '{0}' while writing checksum file '{1}'".format(
                    error.args[1], checksums_paths[0]))
    return hashed_bytes


def human_readable_size(value):  # {{{1
    """ Express the given number of bytes as a binary exponential unit. """

    power = 0
    while value >= 1024 and power <= 4:
        value = value / 1024
        power = power + 1
    return "{0:0.1f} {1}".format(
        value, ["B", "kiB", "MiB", "GiB", "TiB"][power])


def plural(number, singular_form, plural_form=""):  # {{{1
    """ Return the singular or plural form of a string depending on number. """

    if singular_form[-1] == "y" and not plural_form:
        plural_form = singular_form[0:-1] + "ies"

    if number == 1:
        return singular_form
    elif plural_form:
        return plural_form
    else:
        return singular_form + "s"


def print_results(duration):  # {{{1
    """ Put all the statistics into a nice tabular format to read. """

    # output stuff, left and right column
    labels, values = [], []

    labels.append(plural(State.dircount, "directory") + " processed")
    values.append(State.dircount)

    if args.skip > 0:
        labels.append("  after skipping")
        values.append(args.skip)

    if State.skipped_overwrites > 0:
        labels.append("  of which skipped due to overwriting")
        values.append(State.skipped_overwrites)

    if State.md5_missing > 0:
        labels.append("{0} without checksum file".format(
            plural(State.md5_missing, "  directory")))
        values.append(State.md5_missing)

    labels.append(plural(State.files, "file") + " hashed")
    values.append(State.files)

    if not args.create:
        if not args.paths:
            labels.append(
                plural(State.passes, "  check passed", "  checks passed"))
            values.append(State.passes)

            labels.append(plural(
                State.passes, "  check failed", "  checks failed"))
            values.append(State.fails)

    if not args.paths:
        labels.append("  hashed bytes")
        values.append("{0} ({1})".format(
            State.total_hashed_bytes,
            human_readable_size(State.total_hashed_bytes)))

    if not args.create:
        if State.not_in_md5 > 0:
            labels.append(plural(
                State.not_in_md5, "file") + " not in any checksum file")
            values.append(State.not_in_md5)

        if State.files_missing > 0:
            labels.append("listed {0} missing".format(
                plural(State.files_missing, "file")))
            values.append(State.files_missing)

    # --paths is fast, we don’t need time stats and total_hashed_bytes == 0
    if not args.create:
        labels.append("time elapsed")
        values.append("{0:3.1f} seconds ({1:0.1f} MiB/second)".format(
            duration,
            State.total_hashed_bytes / 1048576 / duration if duration != 0
            else 0))

    # get maximum width of items for both columns
    labelwidth = max(len(label) for label in labels)
    valuewidth = math.floor(max(
        0 if value == 0 or isinstance(value, str) else
        math.log10(value) for value in values)) + 1
    formatstring = "{0:" + str(labelwidth) + "}: {1:>" + str(valuewidth) + "}"

    # separation line between process output and result table
    if args.quiet < 3 and any(
            (State.not_in_md5, State.files_missing, State.md5_missing,
             State.files, State.dircount)
    ) or State.question_asked:
        print("-" * (labelwidth + valuewidth + 2))

    # print results
    for label, value in zip(labels, values):
        print(formatstring.format(label, value))


def main():  # {{{1
    """ This is where everything comes together. """

    # recurse every given directory
    try:
        dirlist = []
        starttime = time.time()
        if not args.quiet:
            OUT("Gathering list of files...")
        for location in args.locations:
            location = os.path.abspath(location)
            total_size = gather_files(location, dirlist)

        # find out how many characters are needed for the file count column
        width = max([len(directory[2]) for directory in dirlist])
        width = math.floor(math.log10(width) + 1)
        filecount = sum([len(directory[2]) for directory in dirlist])

        if not args.quiet:
            if args.paths:
                OUT("Checking consistency between checksum files and "
                    "{0} {1} in {2} {3}".format(
                        filecount, plural(filecount, "file"),
                        len(dirlist), plural(len(dirlist), "directory")))
            else:
                OUT("Hashing {0} {1} in {2} {3} ({4})".format(
                    filecount, plural(filecount, "file"),
                    len(dirlist), plural(len(dirlist), "directory"),
                    human_readable_size(total_size)))

        for directory in dirlist:
            State.total_hashed_bytes += process_files(
                width, directory[0], directory[2], directory[3])
            State.dircount += 1
    except KeyboardInterrupt:
        if args.create:
            OUT("\nHashing aborted.")
        else:
            OUT("\nCheck aborted.")
    except RecursionException:
        pass
    finally:
        endtime = time.time()
        duration = endtime - starttime

    Output.clear_dot()
    print_results(duration)

    if any([
            State.fails, State.files_missing,
            State.not_in_md5, State.md5_missing
        ]):
        exit(1)


if __name__ == "__main__":  # {{{1
    main()
